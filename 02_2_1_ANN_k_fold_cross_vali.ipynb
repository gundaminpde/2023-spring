{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCkw8ys+Un34AfmY4LJ3BH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gundaminpde/2023-spring/blob/main/02_2_1_ANN_k_fold_cross_vali.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **0. 전처리**"
      ],
      "metadata": {
        "id": "blblvGqAlnQ5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "wLQzNI03zM8c",
        "outputId": "d94bc876-e96c-4b43-a54a-1d5578007475"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
              "0    842302         M        17.99         10.38          122.80     1001.0   \n",
              "1    842517         M        20.57         17.77          132.90     1326.0   \n",
              "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
              "3  84348301         M        11.42         20.38           77.58      386.1   \n",
              "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
              "\n",
              "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0          0.11840           0.27760          0.3001              0.14710   \n",
              "1          0.08474           0.07864          0.0869              0.07017   \n",
              "2          0.10960           0.15990          0.1974              0.12790   \n",
              "3          0.14250           0.28390          0.2414              0.10520   \n",
              "4          0.10030           0.13280          0.1980              0.10430   \n",
              "\n",
              "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
              "0  ...          17.33           184.60      2019.0            0.1622   \n",
              "1  ...          23.41           158.80      1956.0            0.1238   \n",
              "2  ...          25.53           152.50      1709.0            0.1444   \n",
              "3  ...          26.50            98.87       567.7            0.2098   \n",
              "4  ...          16.67           152.20      1575.0            0.1374   \n",
              "\n",
              "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
              "0             0.6656           0.7119                0.2654          0.4601   \n",
              "1             0.1866           0.2416                0.1860          0.2750   \n",
              "2             0.4245           0.4504                0.2430          0.3613   \n",
              "3             0.8663           0.6869                0.2575          0.6638   \n",
              "4             0.2050           0.4000                0.1625          0.2364   \n",
              "\n",
              "   fractal_dimension_worst  Unnamed: 32  \n",
              "0                  0.11890          NaN  \n",
              "1                  0.08902          NaN  \n",
              "2                  0.08758          NaN  \n",
              "3                  0.17300          NaN  \n",
              "4                  0.07678          NaN  \n",
              "\n",
              "[5 rows x 33 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7c861fda-b83c-4bde-89c1-20ff3b17b79c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>...</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>...</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>...</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>...</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 33 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c861fda-b83c-4bde-89c1-20ff3b17b79c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7c861fda-b83c-4bde-89c1-20ff3b17b79c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7c861fda-b83c-4bde-89c1-20ff3b17b79c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "### from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "Url_B_cancer=\"https://raw.githubusercontent.com/gundaminpde/2023-spring/main/Dset_Breast%20Cancer_Wisconsin.csv\"\n",
        "\n",
        "\n",
        "df = pd.read_csv(Url_B_cancer)\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attribute Information:\n",
        "\n",
        "* Diagnosis (M = malignant, B = benign)\n",
        "\n"
      ],
      "metadata": {
        "id": "90vEdrGLmLhF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NPuxZO80AXB",
        "outputId": "775df3e1-4cc8-4aa0-c49a-588f5e644326"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 33 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   id                       569 non-null    int64  \n",
            " 1   diagnosis                569 non-null    object \n",
            " 2   radius_mean              569 non-null    float64\n",
            " 3   texture_mean             569 non-null    float64\n",
            " 4   perimeter_mean           569 non-null    float64\n",
            " 5   area_mean                569 non-null    float64\n",
            " 6   smoothness_mean          569 non-null    float64\n",
            " 7   compactness_mean         569 non-null    float64\n",
            " 8   concavity_mean           569 non-null    float64\n",
            " 9   concave points_mean      569 non-null    float64\n",
            " 10  symmetry_mean            569 non-null    float64\n",
            " 11  fractal_dimension_mean   569 non-null    float64\n",
            " 12  radius_se                569 non-null    float64\n",
            " 13  texture_se               569 non-null    float64\n",
            " 14  perimeter_se             569 non-null    float64\n",
            " 15  area_se                  569 non-null    float64\n",
            " 16  smoothness_se            569 non-null    float64\n",
            " 17  compactness_se           569 non-null    float64\n",
            " 18  concavity_se             569 non-null    float64\n",
            " 19  concave points_se        569 non-null    float64\n",
            " 20  symmetry_se              569 non-null    float64\n",
            " 21  fractal_dimension_se     569 non-null    float64\n",
            " 22  radius_worst             569 non-null    float64\n",
            " 23  texture_worst            569 non-null    float64\n",
            " 24  perimeter_worst          569 non-null    float64\n",
            " 25  area_worst               569 non-null    float64\n",
            " 26  smoothness_worst         569 non-null    float64\n",
            " 27  compactness_worst        569 non-null    float64\n",
            " 28  concavity_worst          569 non-null    float64\n",
            " 29  concave points_worst     569 non-null    float64\n",
            " 30  symmetry_worst           569 non-null    float64\n",
            " 31  fractal_dimension_worst  569 non-null    float64\n",
            " 32  Unnamed: 32              0 non-null      float64\n",
            "dtypes: float64(31), int64(1), object(1)\n",
            "memory usage: 146.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.drop(['id',\"Unnamed: 32\"],axis=1)"
      ],
      "metadata": {
        "id": "NXR06n2g0M7e"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4rcbpRD0r3M",
        "outputId": "7992d5d2-a8b8-43b6-8e32-4f4e4a0f77a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 31 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   diagnosis                569 non-null    object \n",
            " 1   radius_mean              569 non-null    float64\n",
            " 2   texture_mean             569 non-null    float64\n",
            " 3   perimeter_mean           569 non-null    float64\n",
            " 4   area_mean                569 non-null    float64\n",
            " 5   smoothness_mean          569 non-null    float64\n",
            " 6   compactness_mean         569 non-null    float64\n",
            " 7   concavity_mean           569 non-null    float64\n",
            " 8   concave points_mean      569 non-null    float64\n",
            " 9   symmetry_mean            569 non-null    float64\n",
            " 10  fractal_dimension_mean   569 non-null    float64\n",
            " 11  radius_se                569 non-null    float64\n",
            " 12  texture_se               569 non-null    float64\n",
            " 13  perimeter_se             569 non-null    float64\n",
            " 14  area_se                  569 non-null    float64\n",
            " 15  smoothness_se            569 non-null    float64\n",
            " 16  compactness_se           569 non-null    float64\n",
            " 17  concavity_se             569 non-null    float64\n",
            " 18  concave points_se        569 non-null    float64\n",
            " 19  symmetry_se              569 non-null    float64\n",
            " 20  fractal_dimension_se     569 non-null    float64\n",
            " 21  radius_worst             569 non-null    float64\n",
            " 22  texture_worst            569 non-null    float64\n",
            " 23  perimeter_worst          569 non-null    float64\n",
            " 24  area_worst               569 non-null    float64\n",
            " 25  smoothness_worst         569 non-null    float64\n",
            " 26  compactness_worst        569 non-null    float64\n",
            " 27  concavity_worst          569 non-null    float64\n",
            " 28  concave points_worst     569 non-null    float64\n",
            " 29  symmetry_worst           569 non-null    float64\n",
            " 30  fractal_dimension_worst  569 non-null    float64\n",
            "dtypes: float64(30), object(1)\n",
            "memory usage: 137.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_original = df['diagnosis']"
      ],
      "metadata": {
        "id": "fGW-izJh1IV3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_original.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVUBWhKd2ESY",
        "outputId": "50762a37-0db6-45aa-aa5c-66a369db3ee3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    M\n",
              "1    M\n",
              "2    M\n",
              "3    M\n",
              "4    M\n",
              "Name: diagnosis, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_original_2=pd.get_dummies(y_original)\n",
        "\n",
        "y_original_2.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "gdd37RyA2SQH",
        "outputId": "0e9c832b-c73e-4736-ac97-a1e62f6253e3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   B  M\n",
              "0  0  1\n",
              "1  0  1\n",
              "2  0  1\n",
              "3  0  1\n",
              "4  0  1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bb20c06f-fe25-47f8-ad94-0e1d03d25877\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>B</th>\n",
              "      <th>M</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb20c06f-fe25-47f8-ad94-0e1d03d25877')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bb20c06f-fe25-47f8-ad94-0e1d03d25877 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bb20c06f-fe25-47f8-ad94-0e1d03d25877');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df.iloc[:,1:], y_original_2['B'],stratify=y_original_2['B'], random_state=3)"
      ],
      "metadata": {
        "id": "a-0wHqt12xZE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "MEwWQCKA3uu3",
        "outputId": "01030cda-27eb-4b41-fb15-c78815ca2463"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
              "281       11.740         14.02           74.24      427.3          0.07813   \n",
              "78        20.180         23.97          143.70     1245.0          0.12860   \n",
              "248       10.650         25.22           68.01      347.0          0.09657   \n",
              "120       11.410         10.82           73.34      403.3          0.09373   \n",
              "539        7.691         25.44           48.34      170.4          0.08668   \n",
              "\n",
              "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
              "281           0.04340         0.02245              0.02763         0.2101   \n",
              "78            0.34540         0.37540              0.16040         0.2906   \n",
              "248           0.07234         0.02379              0.01615         0.1897   \n",
              "120           0.06685         0.03512              0.02623         0.1667   \n",
              "539           0.11990         0.09252              0.01364         0.2037   \n",
              "\n",
              "     fractal_dimension_mean  ...  radius_worst  texture_worst  \\\n",
              "281                 0.06113  ...        13.310          18.26   \n",
              "78                  0.08142  ...        23.370          31.72   \n",
              "248                 0.06329  ...        12.250          35.19   \n",
              "120                 0.06113  ...        12.820          15.97   \n",
              "539                 0.07751  ...         8.678          31.89   \n",
              "\n",
              "     perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
              "281            84.70       533.7            0.1036             0.0850   \n",
              "78            170.30      1623.0            0.1639             0.6164   \n",
              "248            77.98       455.7            0.1499             0.1398   \n",
              "120            83.74       510.5            0.1548             0.2390   \n",
              "539            54.49       223.6            0.1596             0.3064   \n",
              "\n",
              "     concavity_worst  concave points_worst  symmetry_worst  \\\n",
              "281          0.06735               0.08290          0.3101   \n",
              "78           0.76810               0.25080          0.5440   \n",
              "248          0.11250               0.06136          0.3409   \n",
              "120          0.21020               0.08958          0.3016   \n",
              "539          0.33930               0.05000          0.2790   \n",
              "\n",
              "     fractal_dimension_worst  \n",
              "281                  0.06688  \n",
              "78                   0.09964  \n",
              "248                  0.08147  \n",
              "120                  0.08523  \n",
              "539                  0.10660  \n",
              "\n",
              "[5 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4923c3df-ad04-44c5-8b26-462200f3c555\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>281</th>\n",
              "      <td>11.740</td>\n",
              "      <td>14.02</td>\n",
              "      <td>74.24</td>\n",
              "      <td>427.3</td>\n",
              "      <td>0.07813</td>\n",
              "      <td>0.04340</td>\n",
              "      <td>0.02245</td>\n",
              "      <td>0.02763</td>\n",
              "      <td>0.2101</td>\n",
              "      <td>0.06113</td>\n",
              "      <td>...</td>\n",
              "      <td>13.310</td>\n",
              "      <td>18.26</td>\n",
              "      <td>84.70</td>\n",
              "      <td>533.7</td>\n",
              "      <td>0.1036</td>\n",
              "      <td>0.0850</td>\n",
              "      <td>0.06735</td>\n",
              "      <td>0.08290</td>\n",
              "      <td>0.3101</td>\n",
              "      <td>0.06688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>20.180</td>\n",
              "      <td>23.97</td>\n",
              "      <td>143.70</td>\n",
              "      <td>1245.0</td>\n",
              "      <td>0.12860</td>\n",
              "      <td>0.34540</td>\n",
              "      <td>0.37540</td>\n",
              "      <td>0.16040</td>\n",
              "      <td>0.2906</td>\n",
              "      <td>0.08142</td>\n",
              "      <td>...</td>\n",
              "      <td>23.370</td>\n",
              "      <td>31.72</td>\n",
              "      <td>170.30</td>\n",
              "      <td>1623.0</td>\n",
              "      <td>0.1639</td>\n",
              "      <td>0.6164</td>\n",
              "      <td>0.76810</td>\n",
              "      <td>0.25080</td>\n",
              "      <td>0.5440</td>\n",
              "      <td>0.09964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>10.650</td>\n",
              "      <td>25.22</td>\n",
              "      <td>68.01</td>\n",
              "      <td>347.0</td>\n",
              "      <td>0.09657</td>\n",
              "      <td>0.07234</td>\n",
              "      <td>0.02379</td>\n",
              "      <td>0.01615</td>\n",
              "      <td>0.1897</td>\n",
              "      <td>0.06329</td>\n",
              "      <td>...</td>\n",
              "      <td>12.250</td>\n",
              "      <td>35.19</td>\n",
              "      <td>77.98</td>\n",
              "      <td>455.7</td>\n",
              "      <td>0.1499</td>\n",
              "      <td>0.1398</td>\n",
              "      <td>0.11250</td>\n",
              "      <td>0.06136</td>\n",
              "      <td>0.3409</td>\n",
              "      <td>0.08147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>11.410</td>\n",
              "      <td>10.82</td>\n",
              "      <td>73.34</td>\n",
              "      <td>403.3</td>\n",
              "      <td>0.09373</td>\n",
              "      <td>0.06685</td>\n",
              "      <td>0.03512</td>\n",
              "      <td>0.02623</td>\n",
              "      <td>0.1667</td>\n",
              "      <td>0.06113</td>\n",
              "      <td>...</td>\n",
              "      <td>12.820</td>\n",
              "      <td>15.97</td>\n",
              "      <td>83.74</td>\n",
              "      <td>510.5</td>\n",
              "      <td>0.1548</td>\n",
              "      <td>0.2390</td>\n",
              "      <td>0.21020</td>\n",
              "      <td>0.08958</td>\n",
              "      <td>0.3016</td>\n",
              "      <td>0.08523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>539</th>\n",
              "      <td>7.691</td>\n",
              "      <td>25.44</td>\n",
              "      <td>48.34</td>\n",
              "      <td>170.4</td>\n",
              "      <td>0.08668</td>\n",
              "      <td>0.11990</td>\n",
              "      <td>0.09252</td>\n",
              "      <td>0.01364</td>\n",
              "      <td>0.2037</td>\n",
              "      <td>0.07751</td>\n",
              "      <td>...</td>\n",
              "      <td>8.678</td>\n",
              "      <td>31.89</td>\n",
              "      <td>54.49</td>\n",
              "      <td>223.6</td>\n",
              "      <td>0.1596</td>\n",
              "      <td>0.3064</td>\n",
              "      <td>0.33930</td>\n",
              "      <td>0.05000</td>\n",
              "      <td>0.2790</td>\n",
              "      <td>0.10660</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4923c3df-ad04-44c5-8b26-462200f3c555')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4923c3df-ad04-44c5-8b26-462200f3c555 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4923c3df-ad04-44c5-8b26-462200f3c555');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "std = StandardScaler()\n",
        "std.fit(X_train.iloc[:,0:])\n",
        "X_train.iloc[:,0:]= std.transform(X_train.iloc[:,0:])\n",
        "X_train.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "fUVrb3lw4FnJ",
        "outputId": "d41bb118-807a-496d-908b-d0248eb5b714"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
              "281    -0.671799     -1.230238       -0.723020  -0.642037        -1.279838   \n",
              "78      1.743377      1.080998        2.155806   1.706229         2.313272   \n",
              "248    -0.983712      1.371354       -0.981228  -0.872642         0.032961   \n",
              "120    -0.766231     -1.973550       -0.760321  -0.710960        -0.169227   \n",
              "539    -1.830454      1.422457       -1.796467  -1.379801        -0.671138   \n",
              "\n",
              "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
              "281         -1.144226       -0.832219            -0.540062       1.064630   \n",
              "78           4.626903        3.669741             2.929992       3.990013   \n",
              "248         -0.591192       -0.815127            -0.840101       0.323291   \n",
              "120         -0.696104       -0.670610            -0.576652      -0.512533   \n",
              "539          0.317666        0.061541            -0.905702       0.832053   \n",
              "\n",
              "     fractal_dimension_mean  ...  radius_worst  texture_worst  \\\n",
              "281               -0.213870  ...     -0.603031      -1.210885   \n",
              "78                 2.682433  ...      1.508085       0.993413   \n",
              "248                0.094460  ...     -0.825474       1.561683   \n",
              "120               -0.213870  ...     -0.705858      -1.585910   \n",
              "539                2.124299  ...     -1.575067       1.021254   \n",
              "\n",
              "     perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
              "281        -0.660779   -0.598653         -1.243058          -1.069445   \n",
              "78          1.917078    1.343444          1.400349           2.347860   \n",
              "248        -0.863152   -0.737718          0.786623          -0.717039   \n",
              "120        -0.689689   -0.640016          1.001427          -0.079108   \n",
              "539        -1.570557   -1.151526          1.211847           0.354325   \n",
              "\n",
              "     concavity_worst  concave points_worst  symmetry_worst  \\\n",
              "281        -0.987536             -0.477389        0.329329   \n",
              "78          2.442924              2.111273        4.074589   \n",
              "248        -0.766508             -0.809490        0.822506   \n",
              "120        -0.288227             -0.374398        0.193225   \n",
              "539         0.343771             -0.984637       -0.168651   \n",
              "\n",
              "     fractal_dimension_worst  \n",
              "281                -0.933254  \n",
              "78                  0.910914  \n",
              "248                -0.111935  \n",
              "120                 0.099728  \n",
              "539                 1.302715  \n",
              "\n",
              "[5 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a2b7abc0-99b8-4809-b9ab-23c10e0eb0cc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>281</th>\n",
              "      <td>-0.671799</td>\n",
              "      <td>-1.230238</td>\n",
              "      <td>-0.723020</td>\n",
              "      <td>-0.642037</td>\n",
              "      <td>-1.279838</td>\n",
              "      <td>-1.144226</td>\n",
              "      <td>-0.832219</td>\n",
              "      <td>-0.540062</td>\n",
              "      <td>1.064630</td>\n",
              "      <td>-0.213870</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.603031</td>\n",
              "      <td>-1.210885</td>\n",
              "      <td>-0.660779</td>\n",
              "      <td>-0.598653</td>\n",
              "      <td>-1.243058</td>\n",
              "      <td>-1.069445</td>\n",
              "      <td>-0.987536</td>\n",
              "      <td>-0.477389</td>\n",
              "      <td>0.329329</td>\n",
              "      <td>-0.933254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>1.743377</td>\n",
              "      <td>1.080998</td>\n",
              "      <td>2.155806</td>\n",
              "      <td>1.706229</td>\n",
              "      <td>2.313272</td>\n",
              "      <td>4.626903</td>\n",
              "      <td>3.669741</td>\n",
              "      <td>2.929992</td>\n",
              "      <td>3.990013</td>\n",
              "      <td>2.682433</td>\n",
              "      <td>...</td>\n",
              "      <td>1.508085</td>\n",
              "      <td>0.993413</td>\n",
              "      <td>1.917078</td>\n",
              "      <td>1.343444</td>\n",
              "      <td>1.400349</td>\n",
              "      <td>2.347860</td>\n",
              "      <td>2.442924</td>\n",
              "      <td>2.111273</td>\n",
              "      <td>4.074589</td>\n",
              "      <td>0.910914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>-0.983712</td>\n",
              "      <td>1.371354</td>\n",
              "      <td>-0.981228</td>\n",
              "      <td>-0.872642</td>\n",
              "      <td>0.032961</td>\n",
              "      <td>-0.591192</td>\n",
              "      <td>-0.815127</td>\n",
              "      <td>-0.840101</td>\n",
              "      <td>0.323291</td>\n",
              "      <td>0.094460</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.825474</td>\n",
              "      <td>1.561683</td>\n",
              "      <td>-0.863152</td>\n",
              "      <td>-0.737718</td>\n",
              "      <td>0.786623</td>\n",
              "      <td>-0.717039</td>\n",
              "      <td>-0.766508</td>\n",
              "      <td>-0.809490</td>\n",
              "      <td>0.822506</td>\n",
              "      <td>-0.111935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>-0.766231</td>\n",
              "      <td>-1.973550</td>\n",
              "      <td>-0.760321</td>\n",
              "      <td>-0.710960</td>\n",
              "      <td>-0.169227</td>\n",
              "      <td>-0.696104</td>\n",
              "      <td>-0.670610</td>\n",
              "      <td>-0.576652</td>\n",
              "      <td>-0.512533</td>\n",
              "      <td>-0.213870</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.705858</td>\n",
              "      <td>-1.585910</td>\n",
              "      <td>-0.689689</td>\n",
              "      <td>-0.640016</td>\n",
              "      <td>1.001427</td>\n",
              "      <td>-0.079108</td>\n",
              "      <td>-0.288227</td>\n",
              "      <td>-0.374398</td>\n",
              "      <td>0.193225</td>\n",
              "      <td>0.099728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>539</th>\n",
              "      <td>-1.830454</td>\n",
              "      <td>1.422457</td>\n",
              "      <td>-1.796467</td>\n",
              "      <td>-1.379801</td>\n",
              "      <td>-0.671138</td>\n",
              "      <td>0.317666</td>\n",
              "      <td>0.061541</td>\n",
              "      <td>-0.905702</td>\n",
              "      <td>0.832053</td>\n",
              "      <td>2.124299</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.575067</td>\n",
              "      <td>1.021254</td>\n",
              "      <td>-1.570557</td>\n",
              "      <td>-1.151526</td>\n",
              "      <td>1.211847</td>\n",
              "      <td>0.354325</td>\n",
              "      <td>0.343771</td>\n",
              "      <td>-0.984637</td>\n",
              "      <td>-0.168651</td>\n",
              "      <td>1.302715</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a2b7abc0-99b8-4809-b9ab-23c10e0eb0cc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a2b7abc0-99b8-4809-b9ab-23c10e0eb0cc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a2b7abc0-99b8-4809-b9ab-23c10e0eb0cc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.iloc[:,0:]= std.transform(X_test.iloc[:,0:])\n"
      ],
      "metadata": {
        "id": "dnOrNnkE46C-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "OcZNlq8q5GQu",
        "outputId": "4f5292a1-3e93-4fb8-abf8-bd77a32e58f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
              "373     1.875010     -0.456729        1.786938   1.964691        -0.117256   \n",
              "101    -2.033627     -1.367286       -1.985045  -1.457052         1.487434   \n",
              "187    -0.680384     -0.493895       -0.704784  -0.662139         0.116257   \n",
              "480    -0.551613     -0.298775       -0.555165  -0.561626        -0.372839   \n",
              "191    -0.377056      0.486348       -0.400572  -0.412006        -0.613471   \n",
              "\n",
              "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
              "373          0.082616        0.829151             1.074610      -0.861398   \n",
              "101         -0.527365       -1.118574            -1.262195       0.443213   \n",
              "187         -0.800061       -0.632727            -0.415655      -1.061269   \n",
              "480         -0.475769       -0.746631            -0.863101      -1.250238   \n",
              "191         -0.712156       -0.721631            -0.513665      -0.414414   \n",
              "\n",
              "     fractal_dimension_mean  ...  radius_worst  texture_worst  \\\n",
              "373               -1.120303  ...      1.927790      -0.406791   \n",
              "101                2.219938  ...     -1.732037      -1.001263   \n",
              "187               -0.239564  ...     -0.665986      -0.698295   \n",
              "480                0.030224  ...     -0.596735       0.362912   \n",
              "191                0.034507  ...     -0.510696      -0.352748   \n",
              "\n",
              "     perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
              "373         1.811675    1.919316          1.062799           0.348537   \n",
              "101        -1.693427   -1.219988          1.159242          -0.843082   \n",
              "187        -0.669211   -0.620404          0.015081          -0.947261   \n",
              "480        -0.536403   -0.574227         -0.489052          -0.150490   \n",
              "191        -0.530079   -0.516997         -1.669160          -1.038706   \n",
              "\n",
              "     concavity_worst  concave points_worst  symmetry_worst  \\\n",
              "373         0.718759              1.500725       -0.330374   \n",
              "101        -1.317242             -1.755531        0.058723   \n",
              "187        -0.572650             -0.061106       -0.517717   \n",
              "480        -0.524186             -0.878254       -0.783520   \n",
              "191        -1.063366             -1.019636       -1.146998   \n",
              "\n",
              "     fractal_dimension_worst  \n",
              "373                -0.726658  \n",
              "101                 0.583287  \n",
              "187                -0.703014  \n",
              "480                -0.347241  \n",
              "191                -0.830237  \n",
              "\n",
              "[5 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a702e14a-fc0c-4160-8139-69f591822b51\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>373</th>\n",
              "      <td>1.875010</td>\n",
              "      <td>-0.456729</td>\n",
              "      <td>1.786938</td>\n",
              "      <td>1.964691</td>\n",
              "      <td>-0.117256</td>\n",
              "      <td>0.082616</td>\n",
              "      <td>0.829151</td>\n",
              "      <td>1.074610</td>\n",
              "      <td>-0.861398</td>\n",
              "      <td>-1.120303</td>\n",
              "      <td>...</td>\n",
              "      <td>1.927790</td>\n",
              "      <td>-0.406791</td>\n",
              "      <td>1.811675</td>\n",
              "      <td>1.919316</td>\n",
              "      <td>1.062799</td>\n",
              "      <td>0.348537</td>\n",
              "      <td>0.718759</td>\n",
              "      <td>1.500725</td>\n",
              "      <td>-0.330374</td>\n",
              "      <td>-0.726658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>-2.033627</td>\n",
              "      <td>-1.367286</td>\n",
              "      <td>-1.985045</td>\n",
              "      <td>-1.457052</td>\n",
              "      <td>1.487434</td>\n",
              "      <td>-0.527365</td>\n",
              "      <td>-1.118574</td>\n",
              "      <td>-1.262195</td>\n",
              "      <td>0.443213</td>\n",
              "      <td>2.219938</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.732037</td>\n",
              "      <td>-1.001263</td>\n",
              "      <td>-1.693427</td>\n",
              "      <td>-1.219988</td>\n",
              "      <td>1.159242</td>\n",
              "      <td>-0.843082</td>\n",
              "      <td>-1.317242</td>\n",
              "      <td>-1.755531</td>\n",
              "      <td>0.058723</td>\n",
              "      <td>0.583287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>187</th>\n",
              "      <td>-0.680384</td>\n",
              "      <td>-0.493895</td>\n",
              "      <td>-0.704784</td>\n",
              "      <td>-0.662139</td>\n",
              "      <td>0.116257</td>\n",
              "      <td>-0.800061</td>\n",
              "      <td>-0.632727</td>\n",
              "      <td>-0.415655</td>\n",
              "      <td>-1.061269</td>\n",
              "      <td>-0.239564</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.665986</td>\n",
              "      <td>-0.698295</td>\n",
              "      <td>-0.669211</td>\n",
              "      <td>-0.620404</td>\n",
              "      <td>0.015081</td>\n",
              "      <td>-0.947261</td>\n",
              "      <td>-0.572650</td>\n",
              "      <td>-0.061106</td>\n",
              "      <td>-0.517717</td>\n",
              "      <td>-0.703014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>480</th>\n",
              "      <td>-0.551613</td>\n",
              "      <td>-0.298775</td>\n",
              "      <td>-0.555165</td>\n",
              "      <td>-0.561626</td>\n",
              "      <td>-0.372839</td>\n",
              "      <td>-0.475769</td>\n",
              "      <td>-0.746631</td>\n",
              "      <td>-0.863101</td>\n",
              "      <td>-1.250238</td>\n",
              "      <td>0.030224</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.596735</td>\n",
              "      <td>0.362912</td>\n",
              "      <td>-0.536403</td>\n",
              "      <td>-0.574227</td>\n",
              "      <td>-0.489052</td>\n",
              "      <td>-0.150490</td>\n",
              "      <td>-0.524186</td>\n",
              "      <td>-0.878254</td>\n",
              "      <td>-0.783520</td>\n",
              "      <td>-0.347241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>-0.377056</td>\n",
              "      <td>0.486348</td>\n",
              "      <td>-0.400572</td>\n",
              "      <td>-0.412006</td>\n",
              "      <td>-0.613471</td>\n",
              "      <td>-0.712156</td>\n",
              "      <td>-0.721631</td>\n",
              "      <td>-0.513665</td>\n",
              "      <td>-0.414414</td>\n",
              "      <td>0.034507</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.510696</td>\n",
              "      <td>-0.352748</td>\n",
              "      <td>-0.530079</td>\n",
              "      <td>-0.516997</td>\n",
              "      <td>-1.669160</td>\n",
              "      <td>-1.038706</td>\n",
              "      <td>-1.063366</td>\n",
              "      <td>-1.019636</td>\n",
              "      <td>-1.146998</td>\n",
              "      <td>-0.830237</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a702e14a-fc0c-4160-8139-69f591822b51')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a702e14a-fc0c-4160-8139-69f591822b51 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a702e14a-fc0c-4160-8139-69f591822b51');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAuVJraG53wk",
        "outputId": "5cca6907-2953-45c8-82c9-1e3dbe6d2290"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    426.000000\n",
              "mean       0.626761\n",
              "std        0.484234\n",
              "min        0.000000\n",
              "25%        0.000000\n",
              "50%        1.000000\n",
              "75%        1.000000\n",
              "max        1.000000\n",
              "Name: B, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbifvqYh6CaI",
        "outputId": "18d0e349-9f2a-45f4-9b1d-8ab53f45f842"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    143.000000\n",
              "mean       0.629371\n",
              "std        0.484671\n",
              "min        0.000000\n",
              "25%        0.000000\n",
              "50%        1.000000\n",
              "75%        1.000000\n",
              "max        1.000000\n",
              "Name: B, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_cat = pd.concat([X_train,y_train], axis=1)\n",
        "\n",
        "corr_mat=np.corrcoef(df_cat,rowvar=False)\n",
        "\n",
        "sns.heatmap(corr_mat,linewidth=1,cmap='RdYlGn_r')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "i8KgAd8P7cCT",
        "outputId": "04881e53-cd9c-44f7-81be-637e4488b1e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**채색의 종류**\n",
        "\n",
        "https://matplotlib.org/stable/tutorials/colors/colormaps.html\n",
        "\n"
      ],
      "metadata": {
        "id": "hbEqPDd7lD_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_cat.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "mjjSvg498U9L",
        "outputId": "a92ee569-ffe0-4676-a600-8a8094e96510"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
              "281    -0.671799     -1.230238       -0.723020  -0.642037        -1.279838   \n",
              "78      1.743377      1.080998        2.155806   1.706229         2.313272   \n",
              "248    -0.983712      1.371354       -0.981228  -0.872642         0.032961   \n",
              "120    -0.766231     -1.973550       -0.760321  -0.710960        -0.169227   \n",
              "539    -1.830454      1.422457       -1.796467  -1.379801        -0.671138   \n",
              "\n",
              "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
              "281         -1.144226       -0.832219            -0.540062       1.064630   \n",
              "78           4.626903        3.669741             2.929992       3.990013   \n",
              "248         -0.591192       -0.815127            -0.840101       0.323291   \n",
              "120         -0.696104       -0.670610            -0.576652      -0.512533   \n",
              "539          0.317666        0.061541            -0.905702       0.832053   \n",
              "\n",
              "     fractal_dimension_mean  ...  texture_worst  perimeter_worst  area_worst  \\\n",
              "281               -0.213870  ...      -1.210885        -0.660779   -0.598653   \n",
              "78                 2.682433  ...       0.993413         1.917078    1.343444   \n",
              "248                0.094460  ...       1.561683        -0.863152   -0.737718   \n",
              "120               -0.213870  ...      -1.585910        -0.689689   -0.640016   \n",
              "539                2.124299  ...       1.021254        -1.570557   -1.151526   \n",
              "\n",
              "     smoothness_worst  compactness_worst  concavity_worst  \\\n",
              "281         -1.243058          -1.069445        -0.987536   \n",
              "78           1.400349           2.347860         2.442924   \n",
              "248          0.786623          -0.717039        -0.766508   \n",
              "120          1.001427          -0.079108        -0.288227   \n",
              "539          1.211847           0.354325         0.343771   \n",
              "\n",
              "     concave points_worst  symmetry_worst  fractal_dimension_worst  B  \n",
              "281             -0.477389        0.329329                -0.933254  1  \n",
              "78               2.111273        4.074589                 0.910914  0  \n",
              "248             -0.809490        0.822506                -0.111935  1  \n",
              "120             -0.374398        0.193225                 0.099728  1  \n",
              "539             -0.984637       -0.168651                 1.302715  1  \n",
              "\n",
              "[5 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6a3a983c-cda5-4d2e-b3c0-e03dd12ed0ee\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>B</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>281</th>\n",
              "      <td>-0.671799</td>\n",
              "      <td>-1.230238</td>\n",
              "      <td>-0.723020</td>\n",
              "      <td>-0.642037</td>\n",
              "      <td>-1.279838</td>\n",
              "      <td>-1.144226</td>\n",
              "      <td>-0.832219</td>\n",
              "      <td>-0.540062</td>\n",
              "      <td>1.064630</td>\n",
              "      <td>-0.213870</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.210885</td>\n",
              "      <td>-0.660779</td>\n",
              "      <td>-0.598653</td>\n",
              "      <td>-1.243058</td>\n",
              "      <td>-1.069445</td>\n",
              "      <td>-0.987536</td>\n",
              "      <td>-0.477389</td>\n",
              "      <td>0.329329</td>\n",
              "      <td>-0.933254</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>1.743377</td>\n",
              "      <td>1.080998</td>\n",
              "      <td>2.155806</td>\n",
              "      <td>1.706229</td>\n",
              "      <td>2.313272</td>\n",
              "      <td>4.626903</td>\n",
              "      <td>3.669741</td>\n",
              "      <td>2.929992</td>\n",
              "      <td>3.990013</td>\n",
              "      <td>2.682433</td>\n",
              "      <td>...</td>\n",
              "      <td>0.993413</td>\n",
              "      <td>1.917078</td>\n",
              "      <td>1.343444</td>\n",
              "      <td>1.400349</td>\n",
              "      <td>2.347860</td>\n",
              "      <td>2.442924</td>\n",
              "      <td>2.111273</td>\n",
              "      <td>4.074589</td>\n",
              "      <td>0.910914</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>-0.983712</td>\n",
              "      <td>1.371354</td>\n",
              "      <td>-0.981228</td>\n",
              "      <td>-0.872642</td>\n",
              "      <td>0.032961</td>\n",
              "      <td>-0.591192</td>\n",
              "      <td>-0.815127</td>\n",
              "      <td>-0.840101</td>\n",
              "      <td>0.323291</td>\n",
              "      <td>0.094460</td>\n",
              "      <td>...</td>\n",
              "      <td>1.561683</td>\n",
              "      <td>-0.863152</td>\n",
              "      <td>-0.737718</td>\n",
              "      <td>0.786623</td>\n",
              "      <td>-0.717039</td>\n",
              "      <td>-0.766508</td>\n",
              "      <td>-0.809490</td>\n",
              "      <td>0.822506</td>\n",
              "      <td>-0.111935</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>-0.766231</td>\n",
              "      <td>-1.973550</td>\n",
              "      <td>-0.760321</td>\n",
              "      <td>-0.710960</td>\n",
              "      <td>-0.169227</td>\n",
              "      <td>-0.696104</td>\n",
              "      <td>-0.670610</td>\n",
              "      <td>-0.576652</td>\n",
              "      <td>-0.512533</td>\n",
              "      <td>-0.213870</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.585910</td>\n",
              "      <td>-0.689689</td>\n",
              "      <td>-0.640016</td>\n",
              "      <td>1.001427</td>\n",
              "      <td>-0.079108</td>\n",
              "      <td>-0.288227</td>\n",
              "      <td>-0.374398</td>\n",
              "      <td>0.193225</td>\n",
              "      <td>0.099728</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>539</th>\n",
              "      <td>-1.830454</td>\n",
              "      <td>1.422457</td>\n",
              "      <td>-1.796467</td>\n",
              "      <td>-1.379801</td>\n",
              "      <td>-0.671138</td>\n",
              "      <td>0.317666</td>\n",
              "      <td>0.061541</td>\n",
              "      <td>-0.905702</td>\n",
              "      <td>0.832053</td>\n",
              "      <td>2.124299</td>\n",
              "      <td>...</td>\n",
              "      <td>1.021254</td>\n",
              "      <td>-1.570557</td>\n",
              "      <td>-1.151526</td>\n",
              "      <td>1.211847</td>\n",
              "      <td>0.354325</td>\n",
              "      <td>0.343771</td>\n",
              "      <td>-0.984637</td>\n",
              "      <td>-0.168651</td>\n",
              "      <td>1.302715</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a3a983c-cda5-4d2e-b3c0-e03dd12ed0ee')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6a3a983c-cda5-4d2e-b3c0-e03dd12ed0ee button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6a3a983c-cda5-4d2e-b3c0-e03dd12ed0ee');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYtRjqumA21l",
        "outputId": "58391f83-98df-4492-f2ee-e88a46c1c39c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(426, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. ANN에 k fold cross validation 적용**"
      ],
      "metadata": {
        "id": "zpkLSfudlZoq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential  \n",
        "from tensorflow.keras.layers import Dense    \n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "#from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy\n",
        " \n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "\n",
        "def create_model():\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(4, input_dim=30, activation='relu'))\n",
        "\tmodel.add(Dense(4, activation='relu'))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics='accuracy')\n",
        "\treturn model\n",
        " \n",
        "\n",
        "model = KerasClassifier(build_fn=create_model, epochs=70, batch_size=16, verbose=1)\n",
        "\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "\n",
        "\n",
        "results = cross_val_score(model, X_train, y_train, cv=kfold)\n",
        "\n",
        "print(\"결과\",results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1rOkh0mAQ1s",
        "outputId": "b6f04d9c-b1a2-432c-869b-0d7cf7188290"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/70\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-667098dadc05>:27: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  model = KerasClassifier(build_fn=create_model, epochs=70, batch_size=16, verbose=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22/22 [==============================] - 1s 3ms/step - loss: 0.6153 - accuracy: 0.7324\n",
            "Epoch 2/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.5428 - accuracy: 0.7882\n",
            "Epoch 3/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4801 - accuracy: 0.8412\n",
            "Epoch 4/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.8588\n",
            "Epoch 5/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3843 - accuracy: 0.8824\n",
            "Epoch 6/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3461 - accuracy: 0.8882\n",
            "Epoch 7/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3123 - accuracy: 0.9059\n",
            "Epoch 8/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2829 - accuracy: 0.9206\n",
            "Epoch 9/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2566 - accuracy: 0.9265\n",
            "Epoch 10/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2338 - accuracy: 0.9324\n",
            "Epoch 11/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2144 - accuracy: 0.9382\n",
            "Epoch 12/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1975 - accuracy: 0.9412\n",
            "Epoch 13/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1821 - accuracy: 0.9441\n",
            "Epoch 14/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1681 - accuracy: 0.9471\n",
            "Epoch 15/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1551 - accuracy: 0.9529\n",
            "Epoch 16/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1434 - accuracy: 0.9529\n",
            "Epoch 17/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1324 - accuracy: 0.9529\n",
            "Epoch 18/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1230 - accuracy: 0.9529\n",
            "Epoch 19/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1152 - accuracy: 0.9529\n",
            "Epoch 20/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1080 - accuracy: 0.9588\n",
            "Epoch 21/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1025 - accuracy: 0.9588\n",
            "Epoch 22/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0971 - accuracy: 0.9588\n",
            "Epoch 23/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0914 - accuracy: 0.9618\n",
            "Epoch 24/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0865 - accuracy: 0.9647\n",
            "Epoch 25/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0821 - accuracy: 0.9676\n",
            "Epoch 26/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0777 - accuracy: 0.9735\n",
            "Epoch 27/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0739 - accuracy: 0.9765\n",
            "Epoch 28/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0706 - accuracy: 0.9824\n",
            "Epoch 29/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0681 - accuracy: 0.9824\n",
            "Epoch 30/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0652 - accuracy: 0.9824\n",
            "Epoch 31/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0631 - accuracy: 0.9824\n",
            "Epoch 32/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0602 - accuracy: 0.9853\n",
            "Epoch 33/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0581 - accuracy: 0.9853\n",
            "Epoch 34/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0563 - accuracy: 0.9853\n",
            "Epoch 35/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0547 - accuracy: 0.9882\n",
            "Epoch 36/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0534 - accuracy: 0.9882\n",
            "Epoch 37/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0518 - accuracy: 0.9882\n",
            "Epoch 38/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0505 - accuracy: 0.9882\n",
            "Epoch 39/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0491 - accuracy: 0.9882\n",
            "Epoch 40/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0479 - accuracy: 0.9882\n",
            "Epoch 41/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0466 - accuracy: 0.9882\n",
            "Epoch 42/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0458 - accuracy: 0.9882\n",
            "Epoch 43/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0447 - accuracy: 0.9882\n",
            "Epoch 44/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0435 - accuracy: 0.9882\n",
            "Epoch 45/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0426 - accuracy: 0.9882\n",
            "Epoch 46/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0418 - accuracy: 0.9882\n",
            "Epoch 47/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0412 - accuracy: 0.9882\n",
            "Epoch 48/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0401 - accuracy: 0.9882\n",
            "Epoch 49/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0394 - accuracy: 0.9882\n",
            "Epoch 50/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0383 - accuracy: 0.9882\n",
            "Epoch 51/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0374 - accuracy: 0.9882\n",
            "Epoch 52/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0369 - accuracy: 0.9882\n",
            "Epoch 53/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0361 - accuracy: 0.9882\n",
            "Epoch 54/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0354 - accuracy: 0.9882\n",
            "Epoch 55/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0348 - accuracy: 0.9882\n",
            "Epoch 56/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0342 - accuracy: 0.9882\n",
            "Epoch 57/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0336 - accuracy: 0.9882\n",
            "Epoch 58/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0330 - accuracy: 0.9882\n",
            "Epoch 59/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0323 - accuracy: 0.9882\n",
            "Epoch 60/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0317 - accuracy: 0.9882\n",
            "Epoch 61/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0313 - accuracy: 0.9882\n",
            "Epoch 62/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0306 - accuracy: 0.9882\n",
            "Epoch 63/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0303 - accuracy: 0.9882\n",
            "Epoch 64/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0297 - accuracy: 0.9882\n",
            "Epoch 65/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0291 - accuracy: 0.9882\n",
            "Epoch 66/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0288 - accuracy: 0.9882\n",
            "Epoch 67/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0282 - accuracy: 0.9882\n",
            "Epoch 68/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0279 - accuracy: 0.9882\n",
            "Epoch 69/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0275 - accuracy: 0.9882\n",
            "Epoch 70/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0272 - accuracy: 0.9882\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.2747 - accuracy: 0.9535\n",
            "Epoch 1/70\n",
            "22/22 [==============================] - 1s 2ms/step - loss: 1.0580 - accuracy: 0.5161\n",
            "Epoch 2/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.8545 - accuracy: 0.6041\n",
            "Epoch 3/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.7135 - accuracy: 0.7214\n",
            "Epoch 4/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.6289 - accuracy: 0.8035\n",
            "Epoch 5/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.5739 - accuracy: 0.8504\n",
            "Epoch 6/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.8680\n",
            "Epoch 7/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.8827\n",
            "Epoch 8/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.4006 - accuracy: 0.8974\n",
            "Epoch 9/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3214 - accuracy: 0.9150\n",
            "Epoch 10/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2663 - accuracy: 0.9296\n",
            "Epoch 11/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2282 - accuracy: 0.9296\n",
            "Epoch 12/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2041 - accuracy: 0.9326\n",
            "Epoch 13/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1847 - accuracy: 0.9413\n",
            "Epoch 14/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1699 - accuracy: 0.9501\n",
            "Epoch 15/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1578 - accuracy: 0.9531\n",
            "Epoch 16/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1486 - accuracy: 0.9501\n",
            "Epoch 17/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1401 - accuracy: 0.9531\n",
            "Epoch 18/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1324 - accuracy: 0.9560\n",
            "Epoch 19/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1256 - accuracy: 0.9619\n",
            "Epoch 20/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1209 - accuracy: 0.9619\n",
            "Epoch 21/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1167 - accuracy: 0.9619\n",
            "Epoch 22/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1130 - accuracy: 0.9619\n",
            "Epoch 23/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1093 - accuracy: 0.9648\n",
            "Epoch 24/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1059 - accuracy: 0.9677\n",
            "Epoch 25/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1013 - accuracy: 0.9707\n",
            "Epoch 26/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0976 - accuracy: 0.9736\n",
            "Epoch 27/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0941 - accuracy: 0.9765\n",
            "Epoch 28/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0916 - accuracy: 0.9795\n",
            "Epoch 29/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0892 - accuracy: 0.9795\n",
            "Epoch 30/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0876 - accuracy: 0.9795\n",
            "Epoch 31/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0858 - accuracy: 0.9795\n",
            "Epoch 32/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0842 - accuracy: 0.9795\n",
            "Epoch 33/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0826 - accuracy: 0.9795\n",
            "Epoch 34/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0814 - accuracy: 0.9765\n",
            "Epoch 35/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0798 - accuracy: 0.9795\n",
            "Epoch 36/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0784 - accuracy: 0.9795\n",
            "Epoch 37/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0776 - accuracy: 0.9795\n",
            "Epoch 38/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0764 - accuracy: 0.9795\n",
            "Epoch 39/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0756 - accuracy: 0.9795\n",
            "Epoch 40/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0749 - accuracy: 0.9795\n",
            "Epoch 41/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0738 - accuracy: 0.9795\n",
            "Epoch 42/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0732 - accuracy: 0.9795\n",
            "Epoch 43/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0725 - accuracy: 0.9795\n",
            "Epoch 44/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0718 - accuracy: 0.9795\n",
            "Epoch 45/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0713 - accuracy: 0.9795\n",
            "Epoch 46/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0704 - accuracy: 0.9795\n",
            "Epoch 47/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0696 - accuracy: 0.9795\n",
            "Epoch 48/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0691 - accuracy: 0.9795\n",
            "Epoch 49/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0686 - accuracy: 0.9795\n",
            "Epoch 50/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0678 - accuracy: 0.9824\n",
            "Epoch 51/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0674 - accuracy: 0.9824\n",
            "Epoch 52/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0671 - accuracy: 0.9824\n",
            "Epoch 53/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0667 - accuracy: 0.9824\n",
            "Epoch 54/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0660 - accuracy: 0.9824\n",
            "Epoch 55/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0655 - accuracy: 0.9824\n",
            "Epoch 56/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0651 - accuracy: 0.9824\n",
            "Epoch 57/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0655 - accuracy: 0.9824\n",
            "Epoch 58/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0643 - accuracy: 0.9824\n",
            "Epoch 59/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0640 - accuracy: 0.9824\n",
            "Epoch 60/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0635 - accuracy: 0.9824\n",
            "Epoch 61/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0634 - accuracy: 0.9824\n",
            "Epoch 62/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.9824\n",
            "Epoch 63/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0624 - accuracy: 0.9824\n",
            "Epoch 64/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.9824\n",
            "Epoch 65/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0612 - accuracy: 0.9824\n",
            "Epoch 66/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0611 - accuracy: 0.9824\n",
            "Epoch 67/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0605 - accuracy: 0.9824\n",
            "Epoch 68/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0604 - accuracy: 0.9824\n",
            "Epoch 69/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0604 - accuracy: 0.9824\n",
            "Epoch 70/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0593 - accuracy: 0.9824\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0190 - accuracy: 0.9882\n",
            "Epoch 1/70\n",
            "22/22 [==============================] - 1s 3ms/step - loss: 0.6928 - accuracy: 0.5894\n",
            "Epoch 2/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.6050 - accuracy: 0.8065\n",
            "Epoch 3/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.5388 - accuracy: 0.9150\n",
            "Epoch 4/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4840 - accuracy: 0.9267\n",
            "Epoch 5/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.9384\n",
            "Epoch 6/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3884 - accuracy: 0.9472\n",
            "Epoch 7/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3429 - accuracy: 0.9472\n",
            "Epoch 8/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3010 - accuracy: 0.9501\n",
            "Epoch 9/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2634 - accuracy: 0.9560\n",
            "Epoch 10/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.2324 - accuracy: 0.9619\n",
            "Epoch 11/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.2066 - accuracy: 0.9619\n",
            "Epoch 12/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1856 - accuracy: 0.9648\n",
            "Epoch 13/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1689 - accuracy: 0.9677\n",
            "Epoch 14/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1548 - accuracy: 0.9677\n",
            "Epoch 15/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1433 - accuracy: 0.9677\n",
            "Epoch 16/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1339 - accuracy: 0.9677\n",
            "Epoch 17/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1259 - accuracy: 0.9707\n",
            "Epoch 18/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1188 - accuracy: 0.9707\n",
            "Epoch 19/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1130 - accuracy: 0.9736\n",
            "Epoch 20/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1077 - accuracy: 0.9736\n",
            "Epoch 21/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1033 - accuracy: 0.9736\n",
            "Epoch 22/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0993 - accuracy: 0.9765\n",
            "Epoch 23/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0956 - accuracy: 0.9765\n",
            "Epoch 24/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0920 - accuracy: 0.9765\n",
            "Epoch 25/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0887 - accuracy: 0.9765\n",
            "Epoch 26/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0862 - accuracy: 0.9824\n",
            "Epoch 27/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0833 - accuracy: 0.9824\n",
            "Epoch 28/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0810 - accuracy: 0.9824\n",
            "Epoch 29/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0785 - accuracy: 0.9824\n",
            "Epoch 30/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0763 - accuracy: 0.9824\n",
            "Epoch 31/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0743 - accuracy: 0.9853\n",
            "Epoch 32/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0721 - accuracy: 0.9824\n",
            "Epoch 33/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0703 - accuracy: 0.9853\n",
            "Epoch 34/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0684 - accuracy: 0.9853\n",
            "Epoch 35/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0668 - accuracy: 0.9853\n",
            "Epoch 36/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0651 - accuracy: 0.9883\n",
            "Epoch 37/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0637 - accuracy: 0.9912\n",
            "Epoch 38/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.9912\n",
            "Epoch 39/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0610 - accuracy: 0.9912\n",
            "Epoch 40/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0597 - accuracy: 0.9912\n",
            "Epoch 41/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0586 - accuracy: 0.9912\n",
            "Epoch 42/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0575 - accuracy: 0.9912\n",
            "Epoch 43/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0564 - accuracy: 0.9912\n",
            "Epoch 44/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0555 - accuracy: 0.9912\n",
            "Epoch 45/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0546 - accuracy: 0.9912\n",
            "Epoch 46/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0537 - accuracy: 0.9912\n",
            "Epoch 47/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0526 - accuracy: 0.9912\n",
            "Epoch 48/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0515 - accuracy: 0.9912\n",
            "Epoch 49/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0507 - accuracy: 0.9912\n",
            "Epoch 50/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0497 - accuracy: 0.9912\n",
            "Epoch 51/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0489 - accuracy: 0.9912\n",
            "Epoch 52/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0486 - accuracy: 0.9912\n",
            "Epoch 53/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0473 - accuracy: 0.9912\n",
            "Epoch 54/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0466 - accuracy: 0.9912\n",
            "Epoch 55/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0459 - accuracy: 0.9912\n",
            "Epoch 56/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0452 - accuracy: 0.9912\n",
            "Epoch 57/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0444 - accuracy: 0.9912\n",
            "Epoch 58/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0438 - accuracy: 0.9912\n",
            "Epoch 59/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0433 - accuracy: 0.9912\n",
            "Epoch 60/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0426 - accuracy: 0.9912\n",
            "Epoch 61/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0420 - accuracy: 0.9941\n",
            "Epoch 62/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0412 - accuracy: 0.9941\n",
            "Epoch 63/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0408 - accuracy: 0.9941\n",
            "Epoch 64/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0402 - accuracy: 0.9941\n",
            "Epoch 65/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0397 - accuracy: 0.9941\n",
            "Epoch 66/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0390 - accuracy: 0.9941\n",
            "Epoch 67/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0386 - accuracy: 0.9941\n",
            "Epoch 68/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0382 - accuracy: 0.9941\n",
            "Epoch 69/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0376 - accuracy: 0.9941\n",
            "Epoch 70/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0371 - accuracy: 0.9941\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0875 - accuracy: 0.9765\n",
            "Epoch 1/70\n",
            "22/22 [==============================] - 1s 2ms/step - loss: 0.6911 - accuracy: 0.4340\n",
            "Epoch 2/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.6428 - accuracy: 0.4721\n",
            "Epoch 3/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.6048 - accuracy: 0.5660\n",
            "Epoch 4/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.5709 - accuracy: 0.7331\n",
            "Epoch 5/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.5351 - accuracy: 0.8299\n",
            "Epoch 6/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.9120\n",
            "Epoch 7/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.9560\n",
            "Epoch 8/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.9707\n",
            "Epoch 9/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3917 - accuracy: 0.9736\n",
            "Epoch 10/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.9736\n",
            "Epoch 11/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3426 - accuracy: 0.9736\n",
            "Epoch 12/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3222 - accuracy: 0.9707\n",
            "Epoch 13/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3040 - accuracy: 0.9736\n",
            "Epoch 14/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2871 - accuracy: 0.9765\n",
            "Epoch 15/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2720 - accuracy: 0.9765\n",
            "Epoch 16/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2579 - accuracy: 0.9736\n",
            "Epoch 17/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.9707\n",
            "Epoch 18/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2330 - accuracy: 0.9736\n",
            "Epoch 19/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2217 - accuracy: 0.9795\n",
            "Epoch 20/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2114 - accuracy: 0.9765\n",
            "Epoch 21/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2017 - accuracy: 0.9795\n",
            "Epoch 22/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1927 - accuracy: 0.9824\n",
            "Epoch 23/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1844 - accuracy: 0.9824\n",
            "Epoch 24/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1762 - accuracy: 0.9824\n",
            "Epoch 25/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1690 - accuracy: 0.9824\n",
            "Epoch 26/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1618 - accuracy: 0.9824\n",
            "Epoch 27/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1551 - accuracy: 0.9853\n",
            "Epoch 28/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1487 - accuracy: 0.9824\n",
            "Epoch 29/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1427 - accuracy: 0.9883\n",
            "Epoch 30/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1373 - accuracy: 0.9853\n",
            "Epoch 31/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1318 - accuracy: 0.9883\n",
            "Epoch 32/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1271 - accuracy: 0.9883\n",
            "Epoch 33/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1225 - accuracy: 0.9883\n",
            "Epoch 34/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1183 - accuracy: 0.9883\n",
            "Epoch 35/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1142 - accuracy: 0.9883\n",
            "Epoch 36/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1108 - accuracy: 0.9883\n",
            "Epoch 37/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1069 - accuracy: 0.9883\n",
            "Epoch 38/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1037 - accuracy: 0.9883\n",
            "Epoch 39/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1004 - accuracy: 0.9883\n",
            "Epoch 40/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0975 - accuracy: 0.9883\n",
            "Epoch 41/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0949 - accuracy: 0.9853\n",
            "Epoch 42/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0919 - accuracy: 0.9883\n",
            "Epoch 43/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0894 - accuracy: 0.9883\n",
            "Epoch 44/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0870 - accuracy: 0.9853\n",
            "Epoch 45/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0846 - accuracy: 0.9883\n",
            "Epoch 46/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0825 - accuracy: 0.9883\n",
            "Epoch 47/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0806 - accuracy: 0.9883\n",
            "Epoch 48/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0788 - accuracy: 0.9883\n",
            "Epoch 49/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0765 - accuracy: 0.9883\n",
            "Epoch 50/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0748 - accuracy: 0.9883\n",
            "Epoch 51/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0731 - accuracy: 0.9883\n",
            "Epoch 52/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0712 - accuracy: 0.9883\n",
            "Epoch 53/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0696 - accuracy: 0.9883\n",
            "Epoch 54/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0684 - accuracy: 0.9883\n",
            "Epoch 55/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0666 - accuracy: 0.9883\n",
            "Epoch 56/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0653 - accuracy: 0.9883\n",
            "Epoch 57/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0641 - accuracy: 0.9883\n",
            "Epoch 58/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.9883\n",
            "Epoch 59/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0614 - accuracy: 0.9883\n",
            "Epoch 60/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0603 - accuracy: 0.9883\n",
            "Epoch 61/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0591 - accuracy: 0.9883\n",
            "Epoch 62/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0579 - accuracy: 0.9883\n",
            "Epoch 63/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0569 - accuracy: 0.9883\n",
            "Epoch 64/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0559 - accuracy: 0.9883\n",
            "Epoch 65/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0549 - accuracy: 0.9883\n",
            "Epoch 66/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0539 - accuracy: 0.9883\n",
            "Epoch 67/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0529 - accuracy: 0.9883\n",
            "Epoch 68/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0522 - accuracy: 0.9883\n",
            "Epoch 69/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0512 - accuracy: 0.9883\n",
            "Epoch 70/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0503 - accuracy: 0.9883\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0868 - accuracy: 0.9765\n",
            "Epoch 1/70\n",
            "22/22 [==============================] - 1s 2ms/step - loss: 0.7404 - accuracy: 0.4575\n",
            "Epoch 2/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.6708 - accuracy: 0.6833\n",
            "Epoch 3/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.6232 - accuracy: 0.8035\n",
            "Epoch 4/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.5815 - accuracy: 0.8446\n",
            "Epoch 5/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.5400 - accuracy: 0.8768\n",
            "Epoch 6/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.9120\n",
            "Epoch 7/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.9267\n",
            "Epoch 8/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.4059 - accuracy: 0.9355\n",
            "Epoch 9/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3632 - accuracy: 0.9443\n",
            "Epoch 10/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3229 - accuracy: 0.9443\n",
            "Epoch 11/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2863 - accuracy: 0.9531\n",
            "Epoch 12/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2550 - accuracy: 0.9501\n",
            "Epoch 13/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2269 - accuracy: 0.9531\n",
            "Epoch 14/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2048 - accuracy: 0.9560\n",
            "Epoch 15/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1870 - accuracy: 0.9619\n",
            "Epoch 16/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1726 - accuracy: 0.9619\n",
            "Epoch 17/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1609 - accuracy: 0.9619\n",
            "Epoch 18/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1508 - accuracy: 0.9619\n",
            "Epoch 19/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1423 - accuracy: 0.9648\n",
            "Epoch 20/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1351 - accuracy: 0.9648\n",
            "Epoch 21/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1280 - accuracy: 0.9648\n",
            "Epoch 22/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1214 - accuracy: 0.9648\n",
            "Epoch 23/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1158 - accuracy: 0.9677\n",
            "Epoch 24/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1105 - accuracy: 0.9677\n",
            "Epoch 25/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1058 - accuracy: 0.9736\n",
            "Epoch 26/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1018 - accuracy: 0.9736\n",
            "Epoch 27/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0983 - accuracy: 0.9736\n",
            "Epoch 28/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0951 - accuracy: 0.9736\n",
            "Epoch 29/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0924 - accuracy: 0.9765\n",
            "Epoch 30/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0898 - accuracy: 0.9765\n",
            "Epoch 31/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0875 - accuracy: 0.9765\n",
            "Epoch 32/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0856 - accuracy: 0.9795\n",
            "Epoch 33/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0835 - accuracy: 0.9795\n",
            "Epoch 34/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0819 - accuracy: 0.9795\n",
            "Epoch 35/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0805 - accuracy: 0.9795\n",
            "Epoch 36/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0790 - accuracy: 0.9765\n",
            "Epoch 37/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0774 - accuracy: 0.9824\n",
            "Epoch 38/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0761 - accuracy: 0.9795\n",
            "Epoch 39/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0752 - accuracy: 0.9795\n",
            "Epoch 40/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0739 - accuracy: 0.9795\n",
            "Epoch 41/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0729 - accuracy: 0.9795\n",
            "Epoch 42/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0719 - accuracy: 0.9795\n",
            "Epoch 43/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0711 - accuracy: 0.9795\n",
            "Epoch 44/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0702 - accuracy: 0.9795\n",
            "Epoch 45/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0694 - accuracy: 0.9795\n",
            "Epoch 46/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0687 - accuracy: 0.9824\n",
            "Epoch 47/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0673 - accuracy: 0.9824\n",
            "Epoch 48/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0659 - accuracy: 0.9824\n",
            "Epoch 49/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.9824\n",
            "Epoch 50/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0635 - accuracy: 0.9853\n",
            "Epoch 51/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0625 - accuracy: 0.9853\n",
            "Epoch 52/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.9853\n",
            "Epoch 53/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0606 - accuracy: 0.9853\n",
            "Epoch 54/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0608 - accuracy: 0.9853\n",
            "Epoch 55/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.9853\n",
            "Epoch 56/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0579 - accuracy: 0.9853\n",
            "Epoch 57/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0571 - accuracy: 0.9853\n",
            "Epoch 58/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0563 - accuracy: 0.9853\n",
            "Epoch 59/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0557 - accuracy: 0.9853\n",
            "Epoch 60/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0548 - accuracy: 0.9883\n",
            "Epoch 61/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 0.9883\n",
            "Epoch 62/70\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.0539 - accuracy: 0.9883\n",
            "Epoch 63/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 0.9912\n",
            "Epoch 64/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.9912\n",
            "Epoch 65/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0522 - accuracy: 0.9912\n",
            "Epoch 66/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9883\n",
            "Epoch 67/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9912\n",
            "Epoch 68/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0511 - accuracy: 0.9912\n",
            "Epoch 69/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0506 - accuracy: 0.9912\n",
            "Epoch 70/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0504 - accuracy: 0.9912\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0765 - accuracy: 0.9647\n",
            "결과 [0.95348835 0.98823529 0.97647059 0.97647059 0.96470588]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_predict\n",
        "\n",
        "results_pred = cross_val_predict(model, X_train, y_train, cv=kfold)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daR3wWTEOwRn",
        "outputId": "3e2d0a02-ecb8-4dff-e0f1-a874b52f1150"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/70\n",
            "22/22 [==============================] - 1s 2ms/step - loss: 0.6897 - accuracy: 0.6176\n",
            "Epoch 2/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.6486 - accuracy: 0.6676\n",
            "Epoch 3/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.5975 - accuracy: 0.8029\n",
            "Epoch 4/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.8882\n",
            "Epoch 5/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.9235\n",
            "Epoch 6/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3834 - accuracy: 0.9382\n",
            "Epoch 7/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3177 - accuracy: 0.9441\n",
            "Epoch 8/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2634 - accuracy: 0.9588\n",
            "Epoch 9/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2218 - accuracy: 0.9588\n",
            "Epoch 10/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1904 - accuracy: 0.9647\n",
            "Epoch 11/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1664 - accuracy: 0.9647\n",
            "Epoch 12/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1478 - accuracy: 0.9706\n",
            "Epoch 13/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1332 - accuracy: 0.9706\n",
            "Epoch 14/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1217 - accuracy: 0.9706\n",
            "Epoch 15/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1121 - accuracy: 0.9706\n",
            "Epoch 16/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1040 - accuracy: 0.9706\n",
            "Epoch 17/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0976 - accuracy: 0.9735\n",
            "Epoch 18/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0920 - accuracy: 0.9735\n",
            "Epoch 19/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0872 - accuracy: 0.9735\n",
            "Epoch 20/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0830 - accuracy: 0.9735\n",
            "Epoch 21/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0793 - accuracy: 0.9735\n",
            "Epoch 22/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0759 - accuracy: 0.9765\n",
            "Epoch 23/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0725 - accuracy: 0.9824\n",
            "Epoch 24/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0699 - accuracy: 0.9824\n",
            "Epoch 25/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.9824\n",
            "Epoch 26/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0645 - accuracy: 0.9853\n",
            "Epoch 27/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.9853\n",
            "Epoch 28/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0604 - accuracy: 0.9853\n",
            "Epoch 29/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0582 - accuracy: 0.9853\n",
            "Epoch 30/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0565 - accuracy: 0.9853\n",
            "Epoch 31/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0550 - accuracy: 0.9853\n",
            "Epoch 32/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0537 - accuracy: 0.9853\n",
            "Epoch 33/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0523 - accuracy: 0.9853\n",
            "Epoch 34/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0508 - accuracy: 0.9853\n",
            "Epoch 35/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0498 - accuracy: 0.9853\n",
            "Epoch 36/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0487 - accuracy: 0.9882\n",
            "Epoch 37/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0477 - accuracy: 0.9882\n",
            "Epoch 38/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0465 - accuracy: 0.9882\n",
            "Epoch 39/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0458 - accuracy: 0.9882\n",
            "Epoch 40/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0449 - accuracy: 0.9882\n",
            "Epoch 41/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0441 - accuracy: 0.9882\n",
            "Epoch 42/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0434 - accuracy: 0.9882\n",
            "Epoch 43/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0425 - accuracy: 0.9882\n",
            "Epoch 44/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0417 - accuracy: 0.9912\n",
            "Epoch 45/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0411 - accuracy: 0.9912\n",
            "Epoch 46/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0402 - accuracy: 0.9912\n",
            "Epoch 47/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0397 - accuracy: 0.9882\n",
            "Epoch 48/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0390 - accuracy: 0.9882\n",
            "Epoch 49/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0384 - accuracy: 0.9882\n",
            "Epoch 50/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0378 - accuracy: 0.9882\n",
            "Epoch 51/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0371 - accuracy: 0.9912\n",
            "Epoch 52/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0367 - accuracy: 0.9912\n",
            "Epoch 53/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0362 - accuracy: 0.9882\n",
            "Epoch 54/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0358 - accuracy: 0.9882\n",
            "Epoch 55/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0352 - accuracy: 0.9882\n",
            "Epoch 56/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0349 - accuracy: 0.9882\n",
            "Epoch 57/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0344 - accuracy: 0.9912\n",
            "Epoch 58/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0338 - accuracy: 0.9912\n",
            "Epoch 59/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0328 - accuracy: 0.9912\n",
            "Epoch 60/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0322 - accuracy: 0.9912\n",
            "Epoch 61/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0317 - accuracy: 0.9912\n",
            "Epoch 62/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0310 - accuracy: 0.9882\n",
            "Epoch 63/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0307 - accuracy: 0.9912\n",
            "Epoch 64/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0303 - accuracy: 0.9912\n",
            "Epoch 65/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0298 - accuracy: 0.9912\n",
            "Epoch 66/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0295 - accuracy: 0.9912\n",
            "Epoch 67/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0292 - accuracy: 0.9912\n",
            "Epoch 68/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0288 - accuracy: 0.9882\n",
            "Epoch 69/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0285 - accuracy: 0.9882\n",
            "Epoch 70/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0281 - accuracy: 0.9882\n",
            "3/3 [==============================] - 0s 3ms/step\n",
            "Epoch 1/70\n",
            "22/22 [==============================] - 1s 2ms/step - loss: 0.6132 - accuracy: 0.6305\n",
            "Epoch 2/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.5684 - accuracy: 0.6305\n",
            "Epoch 3/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.6305\n",
            "Epoch 4/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.6305\n",
            "Epoch 5/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.6305\n",
            "Epoch 6/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.8475\n",
            "Epoch 7/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3992 - accuracy: 0.8856\n",
            "Epoch 8/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3807 - accuracy: 0.9091\n",
            "Epoch 9/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3656 - accuracy: 0.9179\n",
            "Epoch 10/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.9208\n",
            "Epoch 11/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3397 - accuracy: 0.9238\n",
            "Epoch 12/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.9267\n",
            "Epoch 13/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3174 - accuracy: 0.9296\n",
            "Epoch 14/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.9326\n",
            "Epoch 15/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2993 - accuracy: 0.9384\n",
            "Epoch 16/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2902 - accuracy: 0.9413\n",
            "Epoch 17/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2816 - accuracy: 0.9413\n",
            "Epoch 18/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2734 - accuracy: 0.9413\n",
            "Epoch 19/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2644 - accuracy: 0.9443\n",
            "Epoch 20/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2563 - accuracy: 0.9531\n",
            "Epoch 21/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2482 - accuracy: 0.9531\n",
            "Epoch 22/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2402 - accuracy: 0.9589\n",
            "Epoch 23/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2330 - accuracy: 0.9619\n",
            "Epoch 24/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2260 - accuracy: 0.9619\n",
            "Epoch 25/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2190 - accuracy: 0.9619\n",
            "Epoch 26/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2122 - accuracy: 0.9619\n",
            "Epoch 27/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2055 - accuracy: 0.9619\n",
            "Epoch 28/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1994 - accuracy: 0.9648\n",
            "Epoch 29/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1941 - accuracy: 0.9648\n",
            "Epoch 30/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1886 - accuracy: 0.9648\n",
            "Epoch 31/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1830 - accuracy: 0.9648\n",
            "Epoch 32/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1777 - accuracy: 0.9677\n",
            "Epoch 33/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1726 - accuracy: 0.9648\n",
            "Epoch 34/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1674 - accuracy: 0.9648\n",
            "Epoch 35/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.9677\n",
            "Epoch 36/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1577 - accuracy: 0.9677\n",
            "Epoch 37/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1532 - accuracy: 0.9677\n",
            "Epoch 38/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.9677\n",
            "Epoch 39/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1450 - accuracy: 0.9677\n",
            "Epoch 40/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1415 - accuracy: 0.9677\n",
            "Epoch 41/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1375 - accuracy: 0.9677\n",
            "Epoch 42/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1341 - accuracy: 0.9677\n",
            "Epoch 43/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1306 - accuracy: 0.9677\n",
            "Epoch 44/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1275 - accuracy: 0.9677\n",
            "Epoch 45/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1244 - accuracy: 0.9707\n",
            "Epoch 46/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1213 - accuracy: 0.9677\n",
            "Epoch 47/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1180 - accuracy: 0.9736\n",
            "Epoch 48/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1156 - accuracy: 0.9736\n",
            "Epoch 49/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1129 - accuracy: 0.9736\n",
            "Epoch 50/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1106 - accuracy: 0.9707\n",
            "Epoch 51/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1078 - accuracy: 0.9765\n",
            "Epoch 52/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1054 - accuracy: 0.9765\n",
            "Epoch 53/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1034 - accuracy: 0.9795\n",
            "Epoch 54/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1012 - accuracy: 0.9795\n",
            "Epoch 55/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0990 - accuracy: 0.9824\n",
            "Epoch 56/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0972 - accuracy: 0.9824\n",
            "Epoch 57/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0948 - accuracy: 0.9824\n",
            "Epoch 58/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0935 - accuracy: 0.9824\n",
            "Epoch 59/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0912 - accuracy: 0.9824\n",
            "Epoch 60/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0896 - accuracy: 0.9824\n",
            "Epoch 61/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0879 - accuracy: 0.9824\n",
            "Epoch 62/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0864 - accuracy: 0.9824\n",
            "Epoch 63/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0841 - accuracy: 0.9824\n",
            "Epoch 64/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0826 - accuracy: 0.9853\n",
            "Epoch 65/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0809 - accuracy: 0.9853\n",
            "Epoch 66/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0794 - accuracy: 0.9853\n",
            "Epoch 67/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0780 - accuracy: 0.9853\n",
            "Epoch 68/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0769 - accuracy: 0.9853\n",
            "Epoch 69/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0753 - accuracy: 0.9853\n",
            "Epoch 70/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0740 - accuracy: 0.9883\n",
            "3/3 [==============================] - 0s 4ms/step\n",
            "Epoch 1/70\n",
            "22/22 [==============================] - 1s 2ms/step - loss: 0.7429 - accuracy: 0.3900\n",
            "Epoch 2/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.6975 - accuracy: 0.6129\n",
            "Epoch 3/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.6557 - accuracy: 0.7859\n",
            "Epoch 4/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.6191 - accuracy: 0.8739\n",
            "Epoch 5/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.5871 - accuracy: 0.9032\n",
            "Epoch 6/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.5551 - accuracy: 0.9179\n",
            "Epoch 7/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.9355\n",
            "Epoch 8/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.9384\n",
            "Epoch 9/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.9443\n",
            "Epoch 10/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.9443\n",
            "Epoch 11/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.9531\n",
            "Epoch 12/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3937 - accuracy: 0.9560\n",
            "Epoch 13/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3606 - accuracy: 0.9619\n",
            "Epoch 14/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3254 - accuracy: 0.9707\n",
            "Epoch 15/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2885 - accuracy: 0.9677\n",
            "Epoch 16/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2540 - accuracy: 0.9677\n",
            "Epoch 17/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2235 - accuracy: 0.9677\n",
            "Epoch 18/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1973 - accuracy: 0.9677\n",
            "Epoch 19/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1756 - accuracy: 0.9707\n",
            "Epoch 20/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1582 - accuracy: 0.9707\n",
            "Epoch 21/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1437 - accuracy: 0.9736\n",
            "Epoch 22/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1320 - accuracy: 0.9736\n",
            "Epoch 23/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1223 - accuracy: 0.9765\n",
            "Epoch 24/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1143 - accuracy: 0.9765\n",
            "Epoch 25/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1070 - accuracy: 0.9765\n",
            "Epoch 26/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1012 - accuracy: 0.9765\n",
            "Epoch 27/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0961 - accuracy: 0.9765\n",
            "Epoch 28/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0923 - accuracy: 0.9765\n",
            "Epoch 29/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0886 - accuracy: 0.9795\n",
            "Epoch 30/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0853 - accuracy: 0.9795\n",
            "Epoch 31/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0822 - accuracy: 0.9824\n",
            "Epoch 32/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0796 - accuracy: 0.9824\n",
            "Epoch 33/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0771 - accuracy: 0.9824\n",
            "Epoch 34/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0753 - accuracy: 0.9853\n",
            "Epoch 35/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0734 - accuracy: 0.9853\n",
            "Epoch 36/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0714 - accuracy: 0.9883\n",
            "Epoch 37/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0700 - accuracy: 0.9883\n",
            "Epoch 38/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0685 - accuracy: 0.9883\n",
            "Epoch 39/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0668 - accuracy: 0.9883\n",
            "Epoch 40/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0655 - accuracy: 0.9883\n",
            "Epoch 41/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0644 - accuracy: 0.9883\n",
            "Epoch 42/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0631 - accuracy: 0.9883\n",
            "Epoch 43/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0616 - accuracy: 0.9883\n",
            "Epoch 44/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0604 - accuracy: 0.9883\n",
            "Epoch 45/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0589 - accuracy: 0.9883\n",
            "Epoch 46/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0576 - accuracy: 0.9912\n",
            "Epoch 47/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0564 - accuracy: 0.9912\n",
            "Epoch 48/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0553 - accuracy: 0.9912\n",
            "Epoch 49/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0542 - accuracy: 0.9912\n",
            "Epoch 50/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0532 - accuracy: 0.9912\n",
            "Epoch 51/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0522 - accuracy: 0.9912\n",
            "Epoch 52/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0511 - accuracy: 0.9912\n",
            "Epoch 53/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0504 - accuracy: 0.9912\n",
            "Epoch 54/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0493 - accuracy: 0.9912\n",
            "Epoch 55/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0484 - accuracy: 0.9912\n",
            "Epoch 56/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0476 - accuracy: 0.9912\n",
            "Epoch 57/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0470 - accuracy: 0.9912\n",
            "Epoch 58/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0464 - accuracy: 0.9912\n",
            "Epoch 59/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0458 - accuracy: 0.9941\n",
            "Epoch 60/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0449 - accuracy: 0.9941\n",
            "Epoch 61/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0443 - accuracy: 0.9941\n",
            "Epoch 62/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0438 - accuracy: 0.9941\n",
            "Epoch 63/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0431 - accuracy: 0.9941\n",
            "Epoch 64/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0427 - accuracy: 0.9941\n",
            "Epoch 65/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0424 - accuracy: 0.9941\n",
            "Epoch 66/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0416 - accuracy: 0.9941\n",
            "Epoch 67/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0412 - accuracy: 0.9941\n",
            "Epoch 68/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0405 - accuracy: 0.9941\n",
            "Epoch 69/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0401 - accuracy: 0.9941\n",
            "Epoch 70/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0395 - accuracy: 0.9941\n",
            "3/3 [==============================] - 0s 3ms/step\n",
            "Epoch 1/70\n",
            "22/22 [==============================] - 1s 2ms/step - loss: 0.7510 - accuracy: 0.4399\n",
            "Epoch 2/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.6699 - accuracy: 0.6628\n",
            "Epoch 3/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.6147 - accuracy: 0.7977\n",
            "Epoch 4/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.5620 - accuracy: 0.8710\n",
            "Epoch 5/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.9062\n",
            "Epoch 6/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.9326\n",
            "Epoch 7/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.4013 - accuracy: 0.9413\n",
            "Epoch 8/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3551 - accuracy: 0.9472\n",
            "Epoch 9/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3146 - accuracy: 0.9501\n",
            "Epoch 10/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2788 - accuracy: 0.9531\n",
            "Epoch 11/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2468 - accuracy: 0.9619\n",
            "Epoch 12/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2199 - accuracy: 0.9648\n",
            "Epoch 13/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1965 - accuracy: 0.9677\n",
            "Epoch 14/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1766 - accuracy: 0.9648\n",
            "Epoch 15/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1599 - accuracy: 0.9677\n",
            "Epoch 16/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1454 - accuracy: 0.9765\n",
            "Epoch 17/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1332 - accuracy: 0.9795\n",
            "Epoch 18/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1236 - accuracy: 0.9795\n",
            "Epoch 19/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1151 - accuracy: 0.9795\n",
            "Epoch 20/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1082 - accuracy: 0.9795\n",
            "Epoch 21/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1022 - accuracy: 0.9795\n",
            "Epoch 22/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0968 - accuracy: 0.9795\n",
            "Epoch 23/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0926 - accuracy: 0.9795\n",
            "Epoch 24/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0887 - accuracy: 0.9795\n",
            "Epoch 25/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0853 - accuracy: 0.9795\n",
            "Epoch 26/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0823 - accuracy: 0.9795\n",
            "Epoch 27/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0797 - accuracy: 0.9795\n",
            "Epoch 28/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0773 - accuracy: 0.9795\n",
            "Epoch 29/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0754 - accuracy: 0.9795\n",
            "Epoch 30/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0734 - accuracy: 0.9795\n",
            "Epoch 31/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0718 - accuracy: 0.9795\n",
            "Epoch 32/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0703 - accuracy: 0.9795\n",
            "Epoch 33/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0689 - accuracy: 0.9795\n",
            "Epoch 34/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0674 - accuracy: 0.9795\n",
            "Epoch 35/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0664 - accuracy: 0.9824\n",
            "Epoch 36/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0652 - accuracy: 0.9795\n",
            "Epoch 37/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0642 - accuracy: 0.9824\n",
            "Epoch 38/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.9795\n",
            "Epoch 39/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.9795\n",
            "Epoch 40/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0614 - accuracy: 0.9795\n",
            "Epoch 41/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0605 - accuracy: 0.9853\n",
            "Epoch 42/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0598 - accuracy: 0.9824\n",
            "Epoch 43/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0591 - accuracy: 0.9853\n",
            "Epoch 44/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0583 - accuracy: 0.9853\n",
            "Epoch 45/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0575 - accuracy: 0.9853\n",
            "Epoch 46/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0568 - accuracy: 0.9853\n",
            "Epoch 47/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0561 - accuracy: 0.9853\n",
            "Epoch 48/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0556 - accuracy: 0.9853\n",
            "Epoch 49/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0550 - accuracy: 0.9853\n",
            "Epoch 50/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0543 - accuracy: 0.9853\n",
            "Epoch 51/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0539 - accuracy: 0.9853\n",
            "Epoch 52/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0531 - accuracy: 0.9853\n",
            "Epoch 53/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0526 - accuracy: 0.9853\n",
            "Epoch 54/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0521 - accuracy: 0.9853\n",
            "Epoch 55/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0514 - accuracy: 0.9853\n",
            "Epoch 56/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0509 - accuracy: 0.9853\n",
            "Epoch 57/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0505 - accuracy: 0.9853\n",
            "Epoch 58/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0499 - accuracy: 0.9853\n",
            "Epoch 59/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0494 - accuracy: 0.9853\n",
            "Epoch 60/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0491 - accuracy: 0.9883\n",
            "Epoch 61/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0482 - accuracy: 0.9853\n",
            "Epoch 62/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0480 - accuracy: 0.9853\n",
            "Epoch 63/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0472 - accuracy: 0.9883\n",
            "Epoch 64/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0467 - accuracy: 0.9883\n",
            "Epoch 65/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0462 - accuracy: 0.9883\n",
            "Epoch 66/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0457 - accuracy: 0.9883\n",
            "Epoch 67/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0451 - accuracy: 0.9883\n",
            "Epoch 68/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0446 - accuracy: 0.9883\n",
            "Epoch 69/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0442 - accuracy: 0.9883\n",
            "Epoch 70/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0438 - accuracy: 0.9883\n",
            "3/3 [==============================] - 0s 3ms/step\n",
            "Epoch 1/70\n",
            "22/22 [==============================] - 1s 2ms/step - loss: 0.7503 - accuracy: 0.3284\n",
            "Epoch 2/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.5044\n",
            "Epoch 3/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.6435 - accuracy: 0.6804\n",
            "Epoch 4/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.6057 - accuracy: 0.7889\n",
            "Epoch 5/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.5720 - accuracy: 0.8446\n",
            "Epoch 6/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.8739\n",
            "Epoch 7/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.8915\n",
            "Epoch 8/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.9150\n",
            "Epoch 9/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.9150\n",
            "Epoch 10/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.4090 - accuracy: 0.9267\n",
            "Epoch 11/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3735 - accuracy: 0.9326\n",
            "Epoch 12/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3385 - accuracy: 0.9326\n",
            "Epoch 13/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3023 - accuracy: 0.9413\n",
            "Epoch 14/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2692 - accuracy: 0.9472\n",
            "Epoch 15/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2387 - accuracy: 0.9589\n",
            "Epoch 16/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2131 - accuracy: 0.9560\n",
            "Epoch 17/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1916 - accuracy: 0.9589\n",
            "Epoch 18/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1743 - accuracy: 0.9619\n",
            "Epoch 19/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1604 - accuracy: 0.9619\n",
            "Epoch 20/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1488 - accuracy: 0.9648\n",
            "Epoch 21/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1391 - accuracy: 0.9707\n",
            "Epoch 22/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1311 - accuracy: 0.9736\n",
            "Epoch 23/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1239 - accuracy: 0.9765\n",
            "Epoch 24/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1182 - accuracy: 0.9765\n",
            "Epoch 25/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1128 - accuracy: 0.9765\n",
            "Epoch 26/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1083 - accuracy: 0.9765\n",
            "Epoch 27/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1045 - accuracy: 0.9765\n",
            "Epoch 28/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.1013 - accuracy: 0.9765\n",
            "Epoch 29/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0981 - accuracy: 0.9765\n",
            "Epoch 30/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0957 - accuracy: 0.9765\n",
            "Epoch 31/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0928 - accuracy: 0.9795\n",
            "Epoch 32/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0906 - accuracy: 0.9795\n",
            "Epoch 33/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0884 - accuracy: 0.9795\n",
            "Epoch 34/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0861 - accuracy: 0.9795\n",
            "Epoch 35/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0840 - accuracy: 0.9795\n",
            "Epoch 36/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0823 - accuracy: 0.9795\n",
            "Epoch 37/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0804 - accuracy: 0.9795\n",
            "Epoch 38/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0783 - accuracy: 0.9795\n",
            "Epoch 39/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0764 - accuracy: 0.9795\n",
            "Epoch 40/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0745 - accuracy: 0.9795\n",
            "Epoch 41/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.9795\n",
            "Epoch 42/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0698 - accuracy: 0.9795\n",
            "Epoch 43/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0677 - accuracy: 0.9795\n",
            "Epoch 44/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0661 - accuracy: 0.9824\n",
            "Epoch 45/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.9824\n",
            "Epoch 46/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0635 - accuracy: 0.9824\n",
            "Epoch 47/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0620 - accuracy: 0.9824\n",
            "Epoch 48/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0611 - accuracy: 0.9824\n",
            "Epoch 49/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0598 - accuracy: 0.9824\n",
            "Epoch 50/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0589 - accuracy: 0.9853\n",
            "Epoch 51/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0579 - accuracy: 0.9853\n",
            "Epoch 52/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0576 - accuracy: 0.9824\n",
            "Epoch 53/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0562 - accuracy: 0.9853\n",
            "Epoch 54/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0555 - accuracy: 0.9883\n",
            "Epoch 55/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0545 - accuracy: 0.9883\n",
            "Epoch 56/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.9883\n",
            "Epoch 57/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0529 - accuracy: 0.9883\n",
            "Epoch 58/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0522 - accuracy: 0.9883\n",
            "Epoch 59/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0514 - accuracy: 0.9883\n",
            "Epoch 60/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0509 - accuracy: 0.9883\n",
            "Epoch 61/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9883\n",
            "Epoch 62/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0495 - accuracy: 0.9883\n",
            "Epoch 63/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0488 - accuracy: 0.9883\n",
            "Epoch 64/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 0.9883\n",
            "Epoch 65/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0477 - accuracy: 0.9883\n",
            "Epoch 66/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0471 - accuracy: 0.9883\n",
            "Epoch 67/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0466 - accuracy: 0.9883\n",
            "Epoch 68/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0460 - accuracy: 0.9883\n",
            "Epoch 69/70\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0455 - accuracy: 0.9883\n",
            "Epoch 70/70\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0451 - accuracy: 0.9883\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f63b08cf1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "confusion_matrix(y_train, results_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s15t07eaPgOA",
        "outputId": "3df00abd-177c-452f-f278-6e77f2bb0a47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[153,   6],\n",
              "       [  6, 261]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "precision_score(y_train, results_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mmb4dn9CSys7",
        "outputId": "ec86b283-41ad-4648-db89-5d0e12d99b4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9775280898876404"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recall_score(y_train, results_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyFFH9ztUG6x",
        "outputId": "ef7149f5-90d3-4eac-c121-fa4e952bbefc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9775280898876404"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**쓸만한 것같아 전체 training dataset에서 학습**"
      ],
      "metadata": {
        "id": "uNIpK-E6s4dU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential  \n",
        "from tensorflow.keras.layers import Dense    \n",
        "\n",
        "\n",
        "model = Sequential()                                                  # 딥러닝 모델의 구조를 결정합니다.\n",
        "model.add(Dense(30, input_dim=30, activation='relu'))\n",
        "model.add(Dense(20, activation='sigmoid'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])  # 딥러닝 모델을 실행합니다.\n",
        "\n",
        "history=model.fit(X_train, y_train, epochs=70, batch_size=16)\n"
      ],
      "metadata": {
        "id": "0LpGdJi1qSIW",
        "outputId": "064668a0-fe13-4043-9a91-30d87f6c2c25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/70\n",
            "27/27 [==============================] - 2s 5ms/step - loss: 0.5750 - binary_accuracy: 0.7887\n",
            "Epoch 2/70\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.4103 - binary_accuracy: 0.8967\n",
            "Epoch 3/70\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.2994 - binary_accuracy: 0.9249\n",
            "Epoch 4/70\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.2275 - binary_accuracy: 0.9437\n",
            "Epoch 5/70\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.1834 - binary_accuracy: 0.9648\n",
            "Epoch 6/70\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.1525 - binary_accuracy: 0.9718\n",
            "Epoch 7/70\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.1312 - binary_accuracy: 0.9718\n",
            "Epoch 8/70\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.1154 - binary_accuracy: 0.9812\n",
            "Epoch 9/70\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.1040 - binary_accuracy: 0.9836\n",
            "Epoch 10/70\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.0953 - binary_accuracy: 0.9836\n",
            "Epoch 11/70\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.0887 - binary_accuracy: 0.9836\n",
            "Epoch 12/70\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.0826 - binary_accuracy: 0.9836\n",
            "Epoch 13/70\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.0779 - binary_accuracy: 0.9836\n",
            "Epoch 14/70\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.0742 - binary_accuracy: 0.9836\n",
            "Epoch 15/70\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.0705 - binary_accuracy: 0.9836\n",
            "Epoch 16/70\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.0672 - binary_accuracy: 0.9836\n",
            "Epoch 17/70\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.0644 - binary_accuracy: 0.9859\n",
            "Epoch 18/70\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.0620 - binary_accuracy: 0.9859\n",
            "Epoch 19/70\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.0600 - binary_accuracy: 0.9859\n",
            "Epoch 20/70\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.0576 - binary_accuracy: 0.9883\n",
            "Epoch 21/70\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.0556 - binary_accuracy: 0.9906\n",
            "Epoch 22/70\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.0540 - binary_accuracy: 0.9906\n",
            "Epoch 23/70\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.0539 - binary_accuracy: 0.9883\n",
            "Epoch 24/70\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.0503 - binary_accuracy: 0.9906\n",
            "Epoch 25/70\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.0488 - binary_accuracy: 0.9906\n",
            "Epoch 26/70\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.0473 - binary_accuracy: 0.9906\n",
            "Epoch 27/70\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 0.0453 - binary_accuracy: 0.9906\n",
            "Epoch 28/70\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.0437 - binary_accuracy: 0.9906\n",
            "Epoch 29/70\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.0432 - binary_accuracy: 0.9859\n",
            "Epoch 30/70\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.0409 - binary_accuracy: 0.9906\n",
            "Epoch 31/70\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.0396 - binary_accuracy: 0.9906\n",
            "Epoch 32/70\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.0380 - binary_accuracy: 0.9906\n",
            "Epoch 33/70\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.0360 - binary_accuracy: 0.9906\n",
            "Epoch 34/70\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.0349 - binary_accuracy: 0.9906\n",
            "Epoch 35/70\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.0329 - binary_accuracy: 0.9906\n",
            "Epoch 36/70\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.0320 - binary_accuracy: 0.9930\n",
            "Epoch 37/70\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.0307 - binary_accuracy: 0.9906\n",
            "Epoch 38/70\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.0293 - binary_accuracy: 0.9930\n",
            "Epoch 39/70\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.0273 - binary_accuracy: 0.9930\n",
            "Epoch 40/70\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.0262 - binary_accuracy: 0.9930\n",
            "Epoch 41/70\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.0246 - binary_accuracy: 0.9930\n",
            "Epoch 42/70\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.0236 - binary_accuracy: 0.9930\n",
            "Epoch 43/70\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.0226 - binary_accuracy: 0.9930\n",
            "Epoch 44/70\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.0210 - binary_accuracy: 0.9930\n",
            "Epoch 45/70\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.0205 - binary_accuracy: 0.9930\n",
            "Epoch 46/70\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.0197 - binary_accuracy: 0.9953\n",
            "Epoch 47/70\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.0183 - binary_accuracy: 0.9953\n",
            "Epoch 48/70\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.0178 - binary_accuracy: 0.9953\n",
            "Epoch 49/70\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.0170 - binary_accuracy: 0.9953\n",
            "Epoch 50/70\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.0162 - binary_accuracy: 0.9977\n",
            "Epoch 51/70\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.0155 - binary_accuracy: 0.9977\n",
            "Epoch 52/70\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.0148 - binary_accuracy: 0.9977\n",
            "Epoch 53/70\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.0145 - binary_accuracy: 1.0000\n",
            "Epoch 54/70\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.0136 - binary_accuracy: 1.0000\n",
            "Epoch 55/70\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.0132 - binary_accuracy: 0.9977\n",
            "Epoch 56/70\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.0123 - binary_accuracy: 1.0000\n",
            "Epoch 57/70\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.0120 - binary_accuracy: 1.0000\n",
            "Epoch 58/70\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.0116 - binary_accuracy: 1.0000\n",
            "Epoch 59/70\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.0111 - binary_accuracy: 1.0000\n",
            "Epoch 60/70\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.0109 - binary_accuracy: 1.0000\n",
            "Epoch 61/70\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.0103 - binary_accuracy: 1.0000\n",
            "Epoch 62/70\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.0101 - binary_accuracy: 1.0000\n",
            "Epoch 63/70\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.0094 - binary_accuracy: 1.0000\n",
            "Epoch 64/70\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.0092 - binary_accuracy: 1.0000\n",
            "Epoch 65/70\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.0087 - binary_accuracy: 1.0000\n",
            "Epoch 66/70\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.0085 - binary_accuracy: 1.0000\n",
            "Epoch 67/70\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.0080 - binary_accuracy: 1.0000\n",
            "Epoch 68/70\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.0077 - binary_accuracy: 1.0000\n",
            "Epoch 69/70\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.0077 - binary_accuracy: 1.0000\n",
            "Epoch 70/70\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 0.0071 - binary_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "pred_source =model.predict(X_test)\n",
        "\n",
        "results_pred_4_test=np.where(pred_source < 0.5, 0, np.where(pred_source > 0.5, 1, pred_source))\n",
        "# results_pred_4_test = (results_pred_4_test_source > 0.5)\n",
        "\n",
        "confusion_matrix(y_test, results_pred_4_test)"
      ],
      "metadata": {
        "id": "5hTpZt2AqREr",
        "outputId": "b3de4508-9ad1-4235-db59-feefe8f38f46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[52,  1],\n",
              "       [ 0, 90]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **또 다른 k-fold validation 방법**"
      ],
      "metadata": {
        "id": "fQboG3w1FXW8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "### k겹 교차 검증\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# 깃허브에 준비된 데이터를 가져옵니다.\n",
        "\n",
        "targetUrl=\"https://raw.githubusercontent.com/gundaminpde/2022/main/sonar3.csv\"\n",
        "\n",
        "\n",
        "# 광물 데이터를 불러옵니다. \n",
        "\n",
        "df = pd.read_csv(targetUrl, header=None)\n",
        "\n",
        "\n",
        "# 음파 관련 속성을 X로, 광물의 종류를 y로 저장합니다.\n",
        "X = df.iloc[:,0:60]\n",
        "y = df.iloc[:,60]\n",
        "\n",
        "# 몇 겹으로 나눌 것인지를 정합니다. \n",
        "k=5\n",
        "\n",
        "# KFold 함수를 불러옵니다. 분할하기 전에 샘플이 치우치지 않도록 섞어 줍니다.\n",
        "kfold = KFold(n_splits=k, shuffle=True)\n",
        "\n",
        "# 정확도가 채워질 빈 리스트를 준비합니다.\n",
        "acc_score = []\n",
        "\n",
        "def model_fn():\n",
        "    model = Sequential() # 딥러닝 모델의 구조를 시작합니다.\n",
        "    model.add(Dense(24, input_dim=60, activation='relu'))\n",
        "    model.add(Dense(10, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    return model\n",
        "\n",
        "# K겹 교차 검증을 이용해 k번의 학습을 실행합니다. \n",
        "for train_index , test_index in kfold.split(X):  # for 문에 의해서 k번 반복합니다. spilt()에 의해 k개의 학습셋, 테스트셋으로 분리됩니다.\n",
        "    X_train , X_test = X.iloc[train_index,:], X.iloc[test_index,:]  \n",
        "    y_train , y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    model = model_fn()\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    history=model.fit(X_train, y_train, epochs=10, batch_size=10, verbose=0) \n",
        "    \n",
        "    accuracy = model.evaluate(X_test, y_test)[1]  # 정확도를 구합니다.\n",
        "    acc_score.append(accuracy)  # 정확도 리스트에 저장합니다.\n",
        "\n",
        "# k번 실시된 정확도의 평균을 구합니다.\n",
        "avg_acc_score = sum(acc_score)/k\n",
        "\n",
        "# 결과를 출력합니다.\n",
        "print('정확도:', acc_score)\n",
        "print('정확도 평균:', avg_acc_score)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFJoRpmPFSEe",
        "outputId": "033fbd2d-a219-4188-92d3-91f20bb37c24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5555 - accuracy: 0.7619\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6261 - accuracy: 0.6667\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.5763 - accuracy: 0.6667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f63aa57cb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6239 - accuracy: 0.8049\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7f63aa7ab9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6368 - accuracy: 0.6585\n",
            "정확도: [0.761904776096344, 0.6666666865348816, 0.6666666865348816, 0.8048780560493469, 0.6585366129875183]\n",
            "정확도 평균: 0.7117305636405945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2JZbZJ-FGHoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Accuarcy 기준(threshold=0.5)를 바꾸기 위해서는 아래를 참고하세요.**\n",
        "\n",
        "https://keras.io/api/metrics/accuracy_metrics/\n",
        "\n",
        "예를 들어 이렇게...\n",
        "\n",
        "\n",
        "```\n",
        "model.compile(optimizer='sgd',loss='mse', \n",
        "              metrics=[tf.keras.metrics.BinaryAccuracy(threshold=0.5)])\n",
        "```\n"
      ],
      "metadata": {
        "id": "4w6Y6YMM0vWw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hVgqx8VfF0mf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}